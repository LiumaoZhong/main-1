\chapter{Syntactic Parsing}
\label{cha:Parsing}

In the previous section we concluded that the choice for or against a specific type of tree language cannot be made a vacuum.
Since regular tree languages can always be translated into strictly local ones, and \emph{vice versa}, we cannot proclaim one of them to be more cognitively real than the other without putting a very elaborate scaffolding of additional assumptions in place.
At this point, we do not know enough about cognition to pick a specific set of assumptions over another, and odds are that in order to distinguish between regular and strictly local tree languages, we would need assumptions that are so specific and fine-grained that they could never be fully backed up via empirical evidence.

A more fruitful strategy is to accept this indeterminacy and make good use of it.
This can take a negative form by no longer expanding time and resources on fruitless efforts to settle this issue, but also a positive one where we switch between these types of tree languages depending on which one serves our purposes best.
Today we will see how strictly local tree languages provide a simple format for designing parsers.


\section{Intersection Parsing}

On a computational level (in Marr's sense), a parser is device that infers the tree structures that a grammar assigns to a given string.
We can make this more precise via the function $\Yield$, which maps every tree to its string yield: a parser is device that takes a grammar $G$ and a string $s \in \Sigma^*$ as input and computes $\invof{\Yield}(s)$ with respect to $G$.
Formally, this amounts to computing $\invof{\Yield}(\setof{s} \cap L^s(G))$.

Conceptualizing parsing in terms of intersection is very elegant as it reduces parsing to basic operations on languages that we are already familiar with.
In particular, if one can construct a grammar $G'$ whose string language is just $s$, and that assigns exactly the same trees to $s$ as $G$, then $\invof{\Yield}(\setof{s} \cap L^s(G))$ is just the tree language generated by $G'$.
For CFG, such a $G'$ is guaranteed to exist because singleton languages are regular, and CFLs are closed under intersection with regular languages.
%
\begin{theorem}
    Let $L_C$ and $L_R$ be a context-free and a regular string language, respectively.
    Then $L_C \cap L_R$ is context-free.
\end{theorem}
%
\begin{proof}
    Our proof relies on three insights:
    %
    \begin{itemize}
        \item $L_C$ is generated by some CFG $G \is \setof{\Sigma_G,S,R}$.
        \item $L_R$ can be represented by a deterministic FSA $A \is \setof{\Sigma_A,Q,q_0,F,\Delta}$.
        \item The states of $A$ can be incorporated into the alphabet of $G$, yielding a grammar $G_A$ that executes both $G$ and $A$ simultaneously.
    \end{itemize}
    %
    The construction proceeds by prefixing every non-terminal $N$ with the state that $A$ assigns to the leftmost symbol in its substring, and similarly suffixing $N$ by the state of the rightmost symbol.
    For the sake of simplicity we assume that $G$ is strictly binary branching and $\emptystring$-free (which does not decrease generative capacity), but the proof is easily adapted to the more general case.

    We first add a rule $S \rewrite\  _{q_0}S_{q_f}$ to $G_A$ for every $q_f$ that is the final state of some accepting run of $A$ over some $s \in L_R$.
    Given a rewrite rule $X \rewrite Y\ Z$ and some other rule with $_p X _q$ on the righthand side, we add $_p X _q \rewrite \ _p Y _u\ _u Z_q$ to $G_A$, where $u$ is some state such that for some run over a string spanned by $X$ that starts with $p$ and ends in $q$ \textsc{i}) the last symbol of the substring spanned by $Y$ ends in $u$, and \textsc{ii}) the first symbol of the substring spanned by $Z$ starts with $u$.
    We do the same if $B$ or $C$ are terminal symbols instead, except that they are not prefixed and suffixed with states.

    Showing the correctness of the procedure is left as an exercise to the reader.
\end{proof}

\begin{examplebox}
    Let $G$ be the CFG with the rewrite rule $S \rewrite A a | SB$, $A \rewrite aa$, $B \rewrite bbb$ and $s$ the string $aaabbb$, which is recognized by the deterministic automaton $A$ below.
    %
    \begin{center}
        \input{./img/tikz/Parsing_Automaton.tikz}
    \end{center}
    %
    In order to determine what trees $G$ assigns to $s$, we construct a refined CFG $G_A$ according to the instructions above.

    First, we add the rewrite rule $S \rewrite \ _0 S _6$, as $6$ is the only final state that $A$ assigns to $aaabbb$ and there are no other strings to consider.
    Since we now have a refined symbol $_0 S _6$ we have to take care of all the rewrite rules with $S$ on the left hand side.
    We add the rule $_0 S _6 \rewrite \ _0 S _3\ _3 B _6$ since $B$ spans a substring $bbb$, which only occurs between the states $3$ and $6$ in $A$'s run over $s$.
    We cannot find any valid state subscripts for $A$ in $_0 S _6 \rewrite A a$ since no string in $L(a)$ allows us to reach state $6$ via an $a$-transition.
    Consequently, we cannot add a refined rule in this case and move on to the rules for $_0 S _3$.
    In this case, the only valid refinement is $_0 S _3 \rewrite \ _0 A _2 a$.

    The full set of rewrite rules is given below.
    %
    \begin{center}
        \begin{tabular}{rcl}
            $_0 S _6$ & \rewrite & $_0 S _3\ _3 B _6$\\
            $_0 S _3$ & \rewrite & $_0 A _2 a$\\
            $_0 A _2$ & \rewrite & $aa$\\
            $_3 B _6$ & \rewrite & $bbb$
        \end{tabular}
    \end{center}
    %
    It is easy to see that $G_A$ generates only $s$ and assigns it the same tree as $G$, \emph{modulo} subscripts.
    %
    \begin{center}
        \begin{forest}
            [$_0 S _6$
                [$_0 S _3$
                    [$_0 A _2$
                        [a]
                        [a]
                    ]
                    [a]
                ]
                [$_3 B _6$
                    [b]
                    [b]
                    [b]
                ]
            ]
        \end{forest}
    \end{center}
\end{examplebox}
%
\Note{What properties must hold of a CFG so that it only assigns a finite number of trees to a string?}
As long as the refined grammar assigns only a finite number of trees to $s$ (which can be guaranteed via two simple restrictions), this set can be generated by simply applying all rewrite rules in all possible orders.
So our intersection approach has indeed succeeded at reducing parsing to generation with a refined grammar.

The procedure is stated for CFGs, but of course we can extend it to regular tree languages.
First we make the hidden alphabet part of the visible alphabet, which turns the refined strictly $2$-local tree grammar into a CFG (we might have to change a few labels to establish a clear distinction between terminal and non-terminal symbols).
This CFG is then refined, and once the set of trees for the input string has been determined, it is lifted back into a regular tree language via a projection that removes the subscripts and those parts of the label that were originally part of the hidden alphabet.
For strictly $k$-local tree languages, we simply construct the corresponding strictly $2$-local tree grammar and proceed as before.
The fact that we can freely translate between these types of tree languages and use CFGs as a baseline for the refinement construction is what makes intersection parsing applicable across the board.

\section{Top-Down Parsing}

\subsection{Definition}
Elegant as intersection parsing may be from a mathematical perspective, it is not a realistic model of human sentence processing.
Its major shortcoming is that the full input string must be known before one can even get started on the grammar refinement.
Human parsing does not work like this, listeners begin inferring structures as soon as they hear the first word, and there is plenty of evidence that they even build structure before the corresponding part of the string has been encountered.
These are two essential properties of human parsing: it is \emph{incremental} and \emph{predictive}.

We need a more procedural model in order to capture these properties.
One of the simplest and best-known models is top-down parsing.
In fact, it is so intuitive that syntax students, for example, have a tendency to automatically use this algorithm when asked to determine if a grammar generates a given sentence.
That's because top-down parsing is still very close to the idea of CFGs as top-down generators.

Suppose you are given the following CFG.
%
\begin{center}
    \begin{tabular}{rrlp{3em}rrl}
        1)  & S   & \rewrite\ NP VP               &  & 
        6)  & Det & \rewrite\ a | the
        \\
        2)  & NP  & \rewrite\ PN                  &  & 
        7)  & N   & \rewrite\ car | truck | anvil
        \\
        3)  & NP  & \rewrite\ Det N               &  & 
        8)  & PN  & \rewrite\ Bugs | Daffy
        \\
        4)  & VP  & \rewrite\ Vi                  &  & 
        9)  & Vi  & \rewrite\ fell over
        \\
        5)  & VP  & \rewrite\ Vt NP               &  & 
        10) & Vt  & \rewrite\ hit
        \\
    \end{tabular}
\end{center}
%
When asked to show that this grammar generates the sentence \emph{The anvil hit Daffy}, you might draw a tree.
But a different method is to provide a tabular depiction of the rewrite process.
%
\begin{center}
    \begin{tabular}{r|l}
        \textbf{string} & \textbf{rule}\\
        S                   & start\\
        NP VP               & S \rewrite\ NP VP\\
        Det N VP            & NP \rewrite\ Det N\\
        the N VP            & Det \rewrite\ the\\
        the anvil VP        & N \rewrite\ anvil\\
        the anvil Vt NP     & VP \rewrite\ Vt NP\\
        the anvil hit NP    & Vt \rewrite\ hit\\
        the anvil hit PN    & NP \rewrite\ PN\\
        the anvil hit Daffy & PN \rewrite Daffy
    \end{tabular}
\end{center}
%
Of course the rewrite rules could also be applied in other orders.
%
\begin{center}
    \begin{tabular}{r|l}
        \textbf{string}     & \textbf{rule}\\
        S                   & start\\
        NP VP               & S \rewrite\ NP VP\\
        NP Vt NP            & VP \rewrite\ Vt NP\\
        NP Vt PN            & NP \rewrite\ PN\\
        NP Vt Daffy         & PN \rewrite Daffy\\
        NP hit Daffy        & Vt \rewrite\ hit\\
        Det N hit Daffy     & NP \rewrite\ Det N\\
        Det anvil hit Daffy & N \rewrite\ anvil\\
        the anvil hit Daffy & Det \rewrite\ the
    \end{tabular}
    %
    \hspace{1em}
    %
    \begin{tabular}{r|l}
        \textbf{string}     & \textbf{rule}\\
        S                   & start\\
        NP VP               & S \rewrite\ NP VP\\
        Det N VP            & NP \rewrite\ Det N\\
        Det N Vt NP         & VP \rewrite\ Vt NP\\
        the N Vt NP         & Det \rewrite\ the\\
        the anvil Vt NP     & N \rewrite\ anvil\\
        the anvil hit NP    & Vt \rewrite\ hit\\
        the anvil hit  PN   & NP \rewrite\ PN\\
        the anvil hit Daffy & PN \rewrite Daffy
    \end{tabular}
\end{center}
%
In all three cases we proceed top-down: non-terminals are replaced by a string of terminals and\slash or non-terminals.
From the perspective of phrase structure trees, the trees are growing from the root towards the leafs.
The difference between the three tables is the order in which non-terminals are rewritten.
%
\begin{itemize}
    \item Table 1: depth-first, left-to-right
    \item Table 2: depth-first, right-to-left
    \item Table 3: breadth-first, left-to-right
\end{itemize}
%
\begin{description}
    \item[depth-first] rewrite some symbol that was introduced during the previous rewriting step
    \item[breadth-first] before rewriting a symbol introduced during rewriting step $j$, all symbols that were introduced at rewriting step $i$ must have been rewritten, for every $i < j$
    \item[left-to-right] if several symbols are eligible to be rewritten, rewrite the leftmost one
    \item[right-to-left] if several symbols are eligible to be rewritten, rewrite the rightmost one
\end{description}

We can visualize the differences between these strategies by annotating phrase structure trees with indices to indicate when a symbol is first introduced (prefix) and when it is rewritten (suffix).
For terminal symbols, which are never rewritten, we stipulate that the suffix is one higher than the prefix.
%
\begin{center}
    \begin{forest}
            [\Lab{S}{1}{2}    
                [\Lab{NP}{2}{3}
                    [\Lab{Det}{3}{4}
                        [\Lab{the}{4}{5}]
                    ]
                    [\Lab{N}{3}{6}
                        [\Lab{anvil}{6}{7}]
                    ]
                ]
                [\Lab{VP}{2}{8}
                    [\Lab{Vt}{8}{9}
                        [\Lab{hit}{9}{10}]
                    ]
                    [\Lab{NP}{8}{11}
                        [\Lab{PN}{11}{12}
                            [\Lab{Daffy}{12}{13}]
                        ]
                    ]
                ]
            ]
    \end{forest}

    \begin{forest}
            [\Lab{S}{1}{2}    
                [\Lab{NP}{2}{9}
                    [\Lab{Det}{9}{12}
                        [\Lab{the}{12}{13}]
                    ]
                    [\Lab{N}{9}{10}
                        [\Lab{anvil}{10}{11}]
                    ]
                ]
                [\Lab{VP}{2}{3}
                    [\Lab{Vt}{3}{7}
                        [\Lab{hit}{7}{8}]
                    ]
                    [\Lab{NP}{3}{4}
                        [\Lab{PN}{4}{5}
                            [\Lab{Daffy}{5}{6}]
                        ]
                    ]
                ]
            ]
    \end{forest}
    %
    \hspace{1em}
    %
    \begin{forest}
            [\Lab{S}{1}{2}    
                [\Lab{NP}{2}{3}
                    [\Lab{Det}{3}{5}
                        [\Lab{the}{5}{6}]
                    ]
                    [\Lab{N}{3}{7}
                        [\Lab{anvil}{7}{8}]
                    ]
                ]
                [\Lab{VP}{2}{4}
                    [\Lab{Vt}{4}{9}
                        [\Lab{hit}{9}{10}]
                    ]
                    [\Lab{NP}{4}{11}
                        [\Lab{PN}{11}{12}
                            [\Lab{Daffy}{12}{13}]
                        ]
                    ]
                ]
            ]
    \end{forest}
\end{center}

The prototypical top-down parser operates depth-first and left-to-right, and is also known as a \emph{recursive descent parser}.
It's behavior can be stated very succinctly in terms of logical inference rules.
This idea was originally called \emph{parsing as deduction} \citep{PereiraWarren83, Shieber.etal95} and was later refined by \citet{Sikkel97}.
Parsing as deduction made it possible to abstract away from implementation-heavy concepts like data structures and memory management in order to state the basic parsing procedure as clearly as possible.
It is also the foundation of \emph{semiring parsing} \citep{Goodman99}, which provides an abstract perspective that unifies various parsers similar to how our monoid perspective in chapter~\ref{cha:PSL} unified a variety of scanners (in fact, a semiring is an algebraic object that combines two monoids in a particular fashion).

The logical inference rules take the form of \emph{parse items} $[i,\beta]$, where
%
\begin{itemize}
    \item $\beta \in \Sigma^*$ is a string of terminal and\slash or non-terminal symbols, and
    \item  $i$ is a position in the string. 
\end{itemize}
%
The parser always starts with the \emph{axiom} $[0,S]$, which represents the assumption that the input string can be obtained by rewriting the start symbol $S$.
The parser accepts a string iff it can use its inference rules from the axiom to the \emph{goal} item $[n,]$, where $n$ is the end of the input string.
The inference rules are as follows:
%
\begin{prooftree}
    \AxiomC{$[i, a \beta]$}
    \LeftLabel{\textbf{Scan}\qquad}
    \RightLabel{$a = w_i$}
    \UnaryInfC{$[i+1, \beta]$}
\end{prooftree}
%
\begin{prooftree}
    \AxiomC{$[i,N \beta]$}
    \LeftLabel{\textbf{Predict}\qquad}
    \RightLabel{$N \rewrite \gamma \in R$}
    \UnaryInfC{$[i, \gamma \beta]$}
\end{prooftree}
%
The scan rule removes a terminal symbol from a parse item if it matches the symbol in the input at the corresponding position.
The predict rule expands non-terminal nodes according to the grammar.
%
\begin{examplebox}[Top-down parse of \emph{The anvil hit Daffy}]
    Let $G$ be the grammar at the beginning of the handout.
    Then a depth-first, left-to-right parse of \emph{The anvil hit Daffy} will proceed as follows, where predict($n$) denotes a prediction step using rule $n$.
    %
    \begin{center}
        \begin{tabular}{r|l}
            \textbf{parse item} & \textbf{inference rule}\\
            $\lbrack$0,S] & axiom\\
            $\lbrack$0,NP VP] & predict(1)\\
            $\lbrack$0,Det N VP] & predict(3)\\
            $\lbrack$0,the N VP] & predict(6)\\
            $\lbrack$1,N VP] & scan\\
            $\lbrack$1,truck VP] & predict(7)\\
            $\lbrack$2,VP] & scan\\
            $\lbrack$2,Vt NP] & predict(5)\\
            $\lbrack$2,hit NP] & predict(10)\\
            $\lbrack$3,NP] & scan\\
            $\lbrack$3,PN] & predict(2)\\
            $\lbrack$3,Daffy] & predict(8)\\
            $\lbrack$4,] & scan
        \end{tabular}
    \end{center}
    %
    Note that the table above only shows the prediction steps leading to a successful parse.
    The parser, on the other hand, applies every possible prediction step.
    So from [0,NP VP,4], for instance, the parser not only predicts [0,Det N VP,4] via rule 3 but also [0,PN VP,4] via rule 2 since both can be applied to NP\@.
\end{examplebox}
%
Without some kind of additional memory, the parser does not actually keep track of the tree structure and merely acts as a recognizer.
But it is fairly simple to assemble the correct tree from the table above as all the needed information is contained in the application of the predict steps.

\subsection{Psycholinguistic Predictions}
The recursive descent parser is clearly incremental, as it can start parsing before we have seen a single input symbol.
This also shows that it is predictive.
In fact, there is no such thing as an non-predictive top-down parser seeing how the parser must build a subtree before it can even start scanning the leafs of the subtree.
But with a few ancillary assumptions, the recursive descent parser can also explain certain shortcomings of human sentence processing such as garden-path effects and center-embedding.
Let us take a closer look at the former.

Garden path effects were one of the first phenomena to be discussed in the psycholinguistic literature.
They arise with sentences that are grammatically well-formed but nonetheless difficult to parse \citep{Frazier79, FrazierRayner82}.
More precisely, a garden path sentence is a sentence $w$ that up to some $w_i$ has a strongly preferred analysis that must be discarded at $w_{i+1}$. 
Here's a list of examples: 
%
\begin{exe}
    \ex \emph{Structural ambiguity}
    \begin{xlist}
        \ex The horse raced past the barn fell.
        \ex The raft floated down the river sank.
        \ex The player tossed a Frisbee smiled.
        \ex The doctor sent for the patient arrived.
        \ex The cotton clothing is made of grows in Mississippi.
        \ex Fat people eat accumulates.
        \ex I convinced her children are noisy.
    \end{xlist}
    %
    \ex \emph{Lexical ambiguity}
    \begin{xlist}
        \ex The old train the young.
        \ex The old man the boat.
        \ex Until the police arrest the drug dealers control the street.
        \ex The dog that I had really loved bones.
        \ex The man who hunts ducks out on weekends.
    \end{xlist}
\end{exe}

\citet{Frazier79} proposes to treat garden path effects as a result of reanalysis: the parser is forced to abandon its current set of hypotheses, backtrack to an earlier point, and build a new structure from there.
If for some reason this process proves too difficult, the parser gets stuck and assigns no structure at all.
Let's try to make \possciteauthor{Frazier79} account precise.

First, we will use prefix trees to represent the parse history, i.e.\ a record of how the parser built a parse table, rejected it at some point, and moved on to the next one.

\begin{examplebox}[Parse Tables as Trees]
Suppose we are once more using the grammar above to parse \emph{the anvil hit Daffy} with a recursive descent parser.
Our parse table starts with [0,S] as usual, from which we can only predict [0,NP VP].
This can be represented as the tree below.
%
\begin{center}
    \begin{forest}
            [{[0,S]}
                [{[0,NP VP]$_{2,3}$}]
            ]
    \end{forest}
\end{center}
%
The node [0, NP VP] has subscripts $2$ and $3$ to indicate that we can use rules 2 and 3 of our CFG to predict new parse items.
Suppose the parser uses predict(3) to create the item [0, Det N VP].
Then this item is added as a daughter of [0, NP VP] to the previous tree, and the subscript 3 is also removed from [0, NP VP].
We do not need to add a subscript to [0, Det N VP] since it is a leaf.
%
\begin{center}
    \begin{forest}
            [{[0, S]}
                [{[0, NP VP]$_{2}$}
                    [{[0, Det N VP]}]
                ]
            ]
    \end{forest}
\end{center}
%
The next step of the parser now depends on how distinct parses are prioritized.
We can either expand the table that ends in [0, Det N VP], or go back to the one ending in [0, NP VP] and apply predict(2).
Suppose we do the latter, so that [0, PN VP] is added as the second daughter of [0, NP VP], which thus loses its last subscript.
%
\begin{center}
    \begin{forest}
            [{[0, S]}
                [{[0, NP VP]}
                    [{[0, Det N VP]}]
                    [{[0, PN VP]}]
                ]
            ]
    \end{forest}
\end{center}
%
Now let's expand [0, Det N VP] again to obtain [0,  the N VP] and then apply a scan step, yielding [1,  N VP].
%
\begin{center}
    \begin{forest}
            [{[0,S]}
                [{[0,NP VP]}
                    [{[0,Det N VP]}
                        [{[0,the N VP]}
                            [{[1,N VP]}]
                        ]
                    ]
                    [{[0,PN VP]}]
                ]
            ]
    \end{forest}
\end{center}
%
If our parser is really smart, it will be able to infer at this point that the scanned word \emph{the} can never be obtained from [0,PN VP] (technically this is achieved by associating every parse item $p$ with a regular expression that describes the possible left edges of the strings that can be derived from $p$).
So the parser can remove [0,PN VP] from the tree, which is tantamount to discarding the parse table where NP was rewritten as PN\@.
%
\begin{center}
    \begin{forest}
            [{[0,S]}
                [{[0,NP VP]}
                    [{[0,Det N VP]}
                        [{[0,the N VP]}
                            [{[1,N VP]}]
                        ]
                    ]
                ]
            ]
    \end{forest}
\end{center}
\end{examplebox}

What makes the prefix tree representation of parse tables appealing is that the construction and prioritization of parse tables can be reduced to strategies for tree building.
The kind of serial parsing envisioned by \citeauthor{Frazier79} corresponds to a depth-first strategy where the parser always builds a single complete parse history rather than multiple partial ones.
If the parse history cannot be expanded anymore, the parser either stops (successful parse) or backtracks to the last choice point in the parse history and tries a different choice instead.
With such a strategy, garden path effects are readily explained by the amount of attempts it takes to find a successful parse.
%
\begin{examplebox}[Backtracking in \emph{the horse raced past the barn fell}]
    Assume we have the following (massively simplified) grammar:
    %
    \begin{center}
        \begin{tabular}{rrlp{2em}rrl}
            1)  & S   & \rewrite NP VP
                & & 
            8)  & Det & \rewrite the
            \\
            2)  & NP  & \rewrite Det N
                & &
            9)  & N   & \rewrite barn
            \\
            3)  & NP  & \rewrite Det N VP$_\mathit{rel}$
                & & 
            10) & N   & \rewrite horse 
            \\
            4)  & VP  & \rewrite V
                & & 
            11) & P   & \rewrite past
            \\
            5)  & VP  & \rewrite V PP
                & & 
            12) & V   & \rewrite fell 
            \\
            6)  & VP$_\mathit{rel}$  & \rewrite V$_\mathit{rel}$ PP
                & & 
            13) & V   & \rewrite raced
            \\
            7)  & PP  & \rewrite P NP
                & & 
            14) & V$_\mathit{rel}$   & \rewrite raced
        \end{tabular}
    \end{center}
    %
    Here's the resulting phrase structure tree for our garden path sentence.
    %
    \begin{center}
        \footnotesize
        \begin{forest}
                [S
                    [NP
                        [Det [the] ]
                        [N [horse] ]
                        [VP$_\mathit{rel}$
                            [V$_\mathit{rel}$ [raced] ]
                            [PP
                                [P [past] ]
                                [NP
                                    [Det [the] ]
                                    [N [barn] ]
                                ]
                            ]
                        ]
                    ]
                    [VP
                        [V [fell] ]
                    ]
                ]
        \end{forest}
    \end{center}
    %
    If the parser prefers NP \rewrite\ Det N over NP \rewrite Det N VP\tsb{\emph{rel}} and operates in a recursive descent fashion, the construction of the first parse table results in the prefix tree below.
    %
    \begin{center}
        \footnotesize
        \begin{forest}
                [{[0, S]}
                [{[0, NP VP]$_3$}
                [{[0, Det N VP]}
                [{[0,the N VP]}
                [{[1, N VP]$_9$}
                [{[1, horse VP]}
                [{[2, VP]$_4$}
                [{[2, V PP]$_{12}$}
                [{[2, raced PP]}
                [{[3, PP]}
                [{[3, P NP]}
                [{[3, past NP]}
                [{[4, NP]$_3$}
                [{[4, Det N]}
                [{[4, the N]}
                [{[5, N]$_{10}$}
                [{[5, barn]}
                [{[6,]}
                ]]]]]]]]]]]]]]]]]]
        \end{forest}
    \end{center}
    %
    Since this parse does not succeed, the parser needs to backtrack.
    The closest choice point is [5,N]$_{10}$, which obviously does not fix the problem of integrating \emph{fell} into the structure, as can be verified after a single scan step.
    The next choice point is [4,NP]$_3$.
    Here the parser still has the option of replacing NP by Det N CP, which won't help much either, but it takes quite a while to realize this because the tree for the parse table obtained by following this option involves a choice point, too.
    %
    \begin{center}
        \footnotesize
        \begin{forest}
                [{[4, NP]}
                    [{[4, Det N VP$_\mathit{rel}$]}
                        [{[4, the N VP$_\mathit{rel}$]}
                            [{[5, N VP$_\mathit{rel}$]}
                                [{[5, barn VP$_\mathit{rel}$]}
                                    [{[6, VP$_\mathit{rel}$]}
                                        [{[6, V$_\mathit{rel}$ PP]}
                                            [{[6, fell PP]}]
                                        ]
                                    ]
                                ]
                                [{[5, horse VP$_\mathit{rel}$]}]
                            ]
                        ]
                    ]
                ]
        \end{forest}
    \end{center}
    %
    Since this venue didn't yield a successful parse either, the parse backtracks to [2,V PP]$_{12}$, and after this fails, to [2,VP]$_4$.
    Once again it is not successful, and the same holds once it expands [1,N VP].
    %
    \begin{center}
        \footnotesize
        \begin{forest}
                [{[2, V PP]}
                    [{[2, fell PP]}]
                ]
        \end{forest}
        %
        \hspace{1em}
        %
        \begin{forest}
            [{[2, VP]}
                [{[2, V]}
                    [{[2, fell]}]
                    [{[2, raced]}]
                ]
            ]
        \end{forest}
        %
        \hspace{1em}
        %
        \begin{forest}
            [{[1, N VP]}
                [{[1, barn VP]}]
            ]
        \end{forest}
    \end{center}
    %
    Only if the parser backtracks all the way to [0, NP VP]$_3$, essentially undoing all its work so far, can it find a working parse.
    %
    \begin{center}
        \footnotesize
        \begin{forest}
                [{[0, NP VP]}
                    [{[0, Det N VP$_\mathit{rel}$ VP]}
                        [{[0, the N VP$_\mathit{rel}$ VP]}
                            [{[1, N VP$_\mathit{rel}$ VP]}
                                {[1, barn VP$_\mathit{rel}$ VP]}
                                [{[1, horse VP$_\mathit{rel}$ VP]}
                                    [{[2, VP$_\mathit{rel}$ VP]}
                                        [{[2, V$_\mathit{rel}$ PP VP]}
                                            [{[3, raced PP VP]}
                                                [{[4, PP VP]}
                                                    [{[4, P NP VP]}
                                                        [{[4, past NP VP]}
                                                            [{[5, NP VP]}
                                                                [{[5, Det N VP]}
                                                                    [{[5, the N VP]}
                                                                        [{[6, N VP]$_{10}$}
                                                                            [{[6, barn VP]}
                                                                                [{[7, VP]}
                                                                                    [{[7, V]$_{13}$}
                                                                                        [{[7, fell]}
                                                                                            [{[7,]}]
                                                                                        ]
                                                                                    ]
                                                                                ]
                                                                            ]
                                                                        ]
                                                                    ]
                                                                ]
                                                            ]
                                                        ]
                                                    ]
                                                ]
                                            ]
                                        ]
                                    ]
                                ]
                            ]
                        ]
                    ]
                ]
        \end{forest}
    \end{center}
    %
    The prefix tree for all the parse histories built by the parser before it encounters a successful parse it much bigger than the simple phrase structure tree for the sentence.
    %
    \begin{center}
        \footnotesize
        \begin{forest}
                [{[0, S]}
                    [{[0, NP VP]}
                        [{[0, Det N VP]}
                            [{[0,  the N VP]}
                                [{[1, N VP]}
                                    [{[1, horse VP]}
                                        [{[2, VP]}
                                            [{[2, V PP]}
                                                [{[2, raced PP]}
                                                    [{[3, PP]}
                                                        [{[3, P NP]}
                                                            [{[3, past NP]}
                                                                [{[4, NP]}
                                                                    [{[4, Det N]}
                                                                        [{[4, the N]}
                                                                            [{[5, N]}
                                                                                [{[5, barn]}
                                                                                    [{[6,]}]
                                                                                ]
                                                                                [{[5, horse]}]
                                                                            ]
                                                                        ]
                                                                    ]
                                                                    [{[4, Det N VP$_\mathit{rel}$]}
                                                                        [{[4, the N VP$_\mathit{rel}$]}
                                                                            [{[5, N VP$_\mathit{rel}$]}
                                                                                [{[5, barn VP$_\mathit{rel}$]}
                                                                                    [{[6, VP$_\mathit{rel}$]}
                                                                                        [{[6, V$_\mathit{rel}$ PP]}
                                                                                            [{[6, fell PP]}]
                                                                                        ]
                                                                                    ]
                                                                                ]
                                                                                [{[5, horse VP$_\mathit{rel}$]}]
                                                                            ]
                                                                        ]
                                                                    ]
                                                                ]
                                                            ]
                                                        ]
                                                    ]
                                                ]
                                                [{[2, fell PP]}]
                                            ]
                                            [{[2, V]}
                                                [{[2, raced]}]
                                                [{[2, fell]}]
                                            ]
                                        ]
                                    ]
                                [{[1, barn VP]}]
                                ]
                            ]
                        ]
                        [{[0, Det N VP$_\mathit{rel}$ VP]}
                            [{[0, the N VP$_\mathit{rel}$ VP]}
                                [{[1, N VP$_\mathit{rel}$ VP]}
                                    {[1, barn VP$_\mathit{rel}$ VP]}
                                    [{[1, horse VP$_\mathit{rel}$ VP]}
                                        [{[2, VP$_\mathit{rel}$ VP]}
                                            [{[2, V$_\mathit{rel}$ PP VP]}
                                                [{[3, raced PP VP]}
                                                    [{[4, PP VP]}
                                                        [{[4, P NP VP]}
                                                            [{[4, past NP VP]}
                                                                [{[5, NP VP]}
                                                                    [{[5, Det N VP]}
                                                                        [{[5, the N VP]}
                                                                            [{[6, N VP]$_{10}$}
                                                                                [{[6, barn VP]}
                                                                                    [{[7, VP]}
                                                                                        [{[7, V]$_{13}$}
                                                                                            [{[7, fell]}
                                                                                                [{[7,]}]
                                                                                            ]
                                                                                        ]
                                                                                    ]
                                                                                ]
                                                                            ]
                                                                        ]
                                                                    ]
                                                                ]
                                                            ]
                                                        ]
                                                    ]
                                                ]
                                            ]
                                        ]
                                    ]
                                ]
                            ]
                        ]
                    ]
                ]
        \end{forest}
    \end{center}
\end{examplebox}
