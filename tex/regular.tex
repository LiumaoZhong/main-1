\chapter{\texorpdfstring{Hidden Alphabets \emph{or} The Horrors of Abstractness}{Hidden Alphabets or The Horrors of Abstractness}}
\label{cha:REG}

\section{Adding a Hidden Alphabet}

\subsection{Refined Strictly Local Grammars}

\begin{definition}[Run]
    Let $\Sigma$ and $Q$ be overt and \emph{hidden} alphabets, respectively.
    Each $q \in Q$ is called a \emph{state}.
    Given a string $w$ over $\Sigma$, a \emph{$(\Sigma,Q)$-run} over $w$ is a total function mapping each node $n$ of $w$ to some $q \in Q$.
    We also say that \emph{$q$ is assigned to $n$}, and we represent the set of all $(\Sigma,Q)$-runs over $w$ by $Q^w$.
    We may omit mention of $\Sigma$ and $Q$ if they are clear from the context.
    Overloading our terminology, we also use run to refer to the image of $w$ under a given run, or the string of pairs $p_1 \cdots p_n$, where each $p_i$ consists of the $i$-th node of $w$ and its image under some fixed $Q$-run.
\end{definition}
%
\begin{examplebox}[Runs Over a Short String]
    Suppose that $Q \is {p,q,r}$ and that $w \is \String{abbca}$.
    Then the set of $Q$-runs over $w$ includes, among others, $qpprq$, $pqrpq$, or even $ppppp$, but not $qppqs$ (because $s \notin Q$), $qpp$ (too few symbols), or $pqrpqr$ (too many symbols).
    If we view runs as strings of pairs, then the three runs and non-runs look as below:
    %
    \begin{center}
        \begin{tabular}{ccccc}
            $q$ & $p$ & $p$ & $r$ & $q$\\
            $a$ & $b$ & $b$ & $c$ & $a$
        \end{tabular}
        %
        \hspace{1em}
        %
        \begin{tabular}{ccccc}
            $p$ & $q$ & $r$ & $p$ & $q$\\
            $a$ & $b$ & $b$ & $c$ & $a$
        \end{tabular}
        %
        \hspace{1em}
        %
        \begin{tabular}{cccccc}
            $p$ & $p$ & $p$ & $p$ & $p$ & \phantom{$r$}\\
            $a$ & $b$ & $b$ & $c$ & $a$ &
        \end{tabular}
        
        \vspace{1em}

        \begin{tabular}{ccccc}
            $q$ & $p$ & $p$ & $q$ & $s$\\
            $a$ & $b$ & $b$ & $c$ & $a$
        \end{tabular}
        %
        \hspace{1em}
        %
        \begin{tabular}{ccccc}
            $q$ & $p$ & $p$ &     &\\
            $a$ & $b$ & $b$ & $c$ & $a$
        \end{tabular}
        %
        \hspace{1em}
        %
        \begin{tabular}{cccccc}
            $p$ & $p$ & $p$ & $p$ & $p$ & $r$\\
            $a$ & $b$ & $b$ & $c$ & $a$ &
        \end{tabular}
    \end{center}
\end{examplebox}

\begin{definition}[Refined Grammar]
    A refined strictly $k$-local grammar $G$ is a finite set of $k$-grams over alphabet $\Sigma \times Q$.
    Such a grammar generates the language $L(G) \is \setof{ w \mid \exists r \in Q^w, \Bigrams[k](r) \subseteq G}$.
    A language is refined strictly $k$-local iff it is generated by a refined strictly $k$-local grammar.
    The class of all refined strictly $k$-local languages is denoted $\SL_k^R$.
\end{definition}
%
\begin{examplebox}[A Refined Grammar for Even Counting]
    Recall that the language $(\String{aa})^+$, which contains all non-empty strings over $a$ whose length is even, is neither strictly local nor strictly piecewise.
    However, it can be generated by a refined strictly $2$-local grammar with only a handful of bigrams.
    %
    \begin{center}
        \begin{tabular}{cccc}
            \kState{eo}{\LeftEdge a} &
            \kState{oe}{a a} &
            \kState{eo}{a a} &
            \kState{ee}{a \RightEdge}
        \end{tabular}
    \end{center}
    %
    This grammar generates $\String{aaaa}$, for instance, because there is a run such that each bigram of that run is licensed by the grammar.
    In contrast, the slightly longer $\String{aaaaa}$ is not generated because every run contains at least one bigram that is not licensed by the grammar.
    We indicate this by not assigning a state to the node for which an irreconcilable conflict arises.
    %
    \begin{center}
        \begin{tabular}{cccccc}
            e & o & e & o & e & e\\
            \LeftEdge & a & a & a & a & \RightEdge
        \end{tabular}
        %
        \hspace{2em}
        %
        \begin{tabular}{ccccccc}
            e & o & e & o & e & o & \\
            \LeftEdge & a & a & a & a & a & \RightEdge
        \end{tabular}
    \end{center}

\end{examplebox}

\subsection{Generative Capacity}

Due to how refined strictly local grammars are defined, they trivially subsume the strictly local grammars as a special case where the hidden alphabet $Q$ contains only one state.
The fact that a refined strictly $2$-local grammar can generate $(\String{aa}^+)$ shows that the inclusion is proper --- refined strictly local grammars are strictly more powerful than strictly local grammars without a hidden alphabet of states.
But this result can be even strengthened: ever strictly local language is refined strictly $2$-local.
%
\begin{lemma}
    $\SL \subsetneq \SL_2^R$
\end{lemma}
%
To see this, just keep in mind that in order to determine the well-formedness of a string with respect to a strictly $k$-local grammar, it suffices to memorize all the $k$-grams in the string and see if all of them are licensed by the grammar.
This was exactly the way our first scanner implementation operated.
In a refined strictly local grammar, we can use the states to keep track of all the $k$-grams, and the only states that can be assigned to the right edge marker $\RightEdge$ are those that represent a subset of the strictly $k$-local grammar.

\begin{proof}
    We already have $\SL_2^R \not\subseteq \SL$ thanks to the example of $(\String{aa})^+$, so it suffices to show $\SL \subseteq \SL_2^R$.
    Let $L \in SL_k$ be a language over alphabet $\Sigma$, and $G$ a positive strictly $k$-local grammar such that $L(G) = L$.
    The grammar $G_2^R$ is the largest subset of $(\Sigma \times Q)^2$ such that
    %
    \begin{itemize}
        \item $Q$ consists of pairs $\tuple{g,S}$, where $g$ is a $k$-gram and $S$ a set of $k$-grams over $\Sigma$,
        \item $\kState{pq}{ab} \in G_2^R$ only if, for $p \is \tuple{g_p,S_p}$ and $q \is \tuple{g_q,S_q}$
            \begin{itemize}
                \item if $a = \LeftEdge$, then $p \is \tuple{\LeftEdge^k, \setof{\LeftEdge^{k-1} \cdot b}}$,
                \item $g_q \is u \cdot b$, where $u \in \Sigma^{k-1}$ and $g_p \is x \cdot u$,
                \item $S_q \is S_p \cup \setof{g_q}$,
                \item $S_q \subseteq G$.
            \end{itemize}
    \end{itemize}
    
    Since $S_q$ must be a subset of $G$, it follows immediately that $L(G^R_2) \subseteq L(G)$. 
    In the other direction, suppose that some $w \in L(G)$ is not contained in $L(G^R_2)$.
    Then there is no $r \in Q^w$ for which $\Bigrams[k](r) \subseteq G^R_2$.
    However, $G^R_2$ is a maximal subset and thus contains every $\kState{pq}{ab}$ unless one of the conditions above is violated.
    But since $w \in L(G)$, $\Bigrams[k](w) \subseteq G$, so $g_p$, $g_q$ and $S_q$ are well-defined, and $S_q \subseteq G$.
\end{proof}

The strategy above can be modified to keep track of subsequences instead of substrings, which entails that every strictly piecewise language is refined strictly $2$-local.
And because $(\String{aa}^+$ is not strictly piecewise but refined strictly $2$-local, we get yet another proper subsumption relation.
%
\begin{lemma}
    $\SP \subsetneq \SL_2^R$
\end{lemma}
%
At this point it shouldn't come as a surprise that even the strict threshold testable languages are refined strictly $2$-local.
%
\begin{lemma}
    $\STT \subsetneq \SL_2^R$
\end{lemma}
%
\begin{proof}
    Left as an exercise to the reader.
\end{proof}

As you can see, the addition of a hidden alphabet has made our formalism much more powerful, to the extent where we can't even make any distinctions between local and non-local dependencies: they all belong to $\SL_2^R$.
And as we will see next, things are even worse insofar as locality plays no role at all in refined strictly local grammars.


\section{The Loss of Locality}

\subsection{Reduction to 2-Locality}

\begin{theorem}
    If a language is generated by a refined strictly $k$-local grammar with hidden alphabet $Q$ ($k \geq 2$) then it is generated by a refined strictly $2$-local grammar with hidden alphabet $Q'$.
    \label{thm:REG_SL2}
\end{theorem}
%
The proof for this theorem is fairly cumbersome to read, but the intuition of the construction is very simple: since a refined strictly $k$-local grammar has only a finite number of $k$-grams, we can emulate the computations of the whole grammar in our hidden alphabet.
%
\begin{examplebox}[Emulating a Grammar via a Hidden Alphabet]
    Let $L$ be the language of all strings over $\setof{a,b}$ such that consecutive substrings of $b$s must have even length and may only occur after at least three $a$s. 
    \label{ex:REG_HiddenTranslation}
    This language includes strings like $\String{aaa}$, $\String{aaabb}$, and $\String{aaabbbba}$, but not $\String{bbaaa}$ or $\String{aaab}$.
    This can be easily handled by a refined strictly $4$-local grammar where the hidden alphabet keeps track of the length requirement while the presence of three $a$s is enforced directly via the $4$-grams.
    The initial $4$-grams are very simple, since no $b$ can occur at the start of a string:
    %
    \[
        \begin{array}{cccc}
            \kState{eeee}{\LeftEdge \LeftEdge \LeftEdge a} &
            \kState{eeee}{\LeftEdge \LeftEdge a a} &
            \kState{eeee}{\LeftEdge a a a} &
        \end{array}
    \]
    %
    The final $4$-grams already have to take quite a bit of variation into account:
    %
    \[
        \begin{array}{cccc}
            \\[12pt]
            \kState{eeee}{a \RightEdge \RightEdge \RightEdge} &
            \kState{eeee}{a a \RightEdge \RightEdge} &
            \kState{eeee}{a a a\RightEdge} &
            \kState{eoee}{a b b\RightEdge}
            \\[12pt]
            \kState{eeee}{b \RightEdge \RightEdge \RightEdge} &
            \kState{eeee}{b a \RightEdge \RightEdge} &
            \kState{eeee}{b a a\RightEdge} &
            \\[12pt]
            \kState{oeee}{b b \RightEdge \RightEdge} &
            \kState{oeee}{b b a \RightEdge} &
            \\[12pt]
            \kState{eoee}{b b b \RightEdge}
        \end{array}
    \]
    %
    The non-initial, non-final $4$-grams are also much fewer than one might expect thanks to the restricted distribution of $b$s:
    %
    \[
        \begin{array}{ccccc}
            \kState{eeee}{aaaa} &
            \kState{eeeo}{aaab} &
            \kState{eeoe}{aabb} &
            \kState{eoee}{abba} &
            \kState{eoeo}{abbb}
            \\[12pt]
            \kState{eoeo}{bbbb} &
            \kState{oeoe}{bbbb} &
            \kState{eoee}{bbba} &
            \kState{oeee}{bbaa} &
            \kState{eeee}{baaa}
        \end{array}
    \]
    %
    Let's quickly verify that this grammar generates the string $\String{aaabb}$ but not $\String{aaabbabb}$ or $\String{aaabbaaab}$.
    %
    \[
        \begin{array}{ccccccccccc}
                e & e & e & e & e & e & o & e & e & e & e\\
                \LeftEdge & \LeftEdge & \LeftEdge & a & a & a & b & b & \RightEdge & \RightEdge & \RightEdge
        \end{array}
    \]
    \[ 
        \begin{array}{ccccccccccccccc}
                e & e & e & e & e & e & o & e & e & e & & & & &\\
                \LeftEdge & \LeftEdge & \LeftEdge & a & a & a & b & b & a & a & b & b &\RightEdge & \RightEdge & \RightEdge
        \end{array}
    \]
    \[ 
        \begin{array}{ccccccccccccccc}
                e & e & e & e & e & e & o & e & e & e & e & o & & &\\
                \LeftEdge & \LeftEdge & \LeftEdge & a & a & a & b & b & a & a & a & b &\RightEdge & \RightEdge & \RightEdge
        \end{array}
    \]
    
    We are now going to convert this grammar into a refined strictly $2$-local one.
    The operation is very simple to carry out: every $4$-gram is first split into two $3$-grams, one of which includes the first three positions, the other one the last three positions.
    We then use these two $3$-grams as the hidden symbols for the $2$-gram that consists of the last two positions of the $4$-gram.
    For example, $\dfrac{eoee}{abba}$ is turned into the bigram below.
    %
    \[
        \dfrac{
            \dfrac{eoe}{abb}
            \dfrac{oee}{bba}
            }
            {
            b\quad a
            }
    \]
    %
    The whole grammar consists of the following bigrams (the translation also produces a few refined bigrams for $\String{\RightEdge \RightEdge}$, but those are never useful in a strictly $2$-local grammar and can safely be discarded):
    \[
        \begin{array}{ccccc}
            \kState{
                \kState{eee}{\LeftEdge \LeftEdge \LeftEdge}
                \kState{eee}{\LeftEdge \LeftEdge a}
                }
                {
                \LeftEdge \quad a
                }
            &
            \kState{
                \kState{eee}{\LeftEdge \LeftEdge a}
                \kState{eee}{\LeftEdge a a}
                }
                {
                a \quad a
                }
            &
            \kState{
                \kState{eee}{\LeftEdge a a}
                \kState{eee}{a a a}
                }
                {
                a \quad a
                }
            \\[12pt]
            \kState{
                \kState{eee}{a a a}
                \kState{eee}{a a \RightEdge}
                }
                {
                a \quad \RightEdge
                }
            &
            \kState{
                \kState{eoe}{a b b}
                \kState{oee}{b b \RightEdge}
                }
                {
                b \quad \RightEdge
                }
            &
            \kState{
                \kState{eee}{b a a}
                \kState{eee}{a a \RightEdge}
                }
                {
                a \quad \RightEdge
                }
            &
            \kState{
                \kState{oee}{b b a}
                \kState{eee}{b a \RightEdge}
                }
                {
                a \quad \RightEdge
                }
            &
            \kState{
                \kState{eoe}{b b b}
                \kState{oee}{b b \RightEdge}
                }
                {
                b \quad \RightEdge
                }
            \\[12pt]
            \kState{
                \kState{eee}{a a a}
                \kState{eee}{a a a}
                }
                {
                a \quad a
                }
            &
            \kState{
                \kState{eee}{a a a}
                \kState{eeo}{a a b}
                }
                {
                a \quad b
                }
            &
            \kState{
                \kState{eeo}{a a b}
                \kState{eoe}{a b b}
                }
                {
                b \quad b
                }
            &
            \kState{
                \kState{eoe}{a b b}
                \kState{oee}{b b a}
                }
                {
                b \quad a
                }
            &
            \kState{
                \kState{eoe}{a b b}
                \kState{oeo}{b b b}
                }
                {
                b \quad b
                }
            \\[12pt]
            \kState{
                \kState{eoe}{b b b}
                \kState{oeo}{b b b}
                }
                {
                b \quad b
                }
            &
            \kState{
                \kState{oeo}{b b b}
                \kState{eoe}{b b b}
                }
                {
                b \quad b
                }
            &
            \kState{
                \kState{eoe}{b b b}
                \kState{oee}{b b a}
                }
                {
                b \quad a
                }
            &
            \kState{
                \kState{oee}{b b a}
                \kState{eee}{b a a}
                }
                {
                a \quad a
                }
            &
            \kState{
                \kState{eee}{b a a}
                \kState{eee}{a a a}
                }
                {
                a \quad a
                }
        \end{array}
    \]
    %
    When we use this grammar to determine the well-formedness of the previous three example strings, we once again see that only the first one has a run and is thus generated by the grammar.
    %
    \[
        \begin{array}{ccccccc}
                \ComplexState{eee}{\LeftEdge \LeftEdge \LeftEdge} &
                \ComplexState{eee}{\LeftEdge \LeftEdge a} &
                \ComplexState{eee}{\LeftEdge a a} &
                \ComplexState{eee}{a a a} &
                \ComplexState{eeo}{a a b} &
                \ComplexState{eoe}{a b b} &
                \ComplexState{oee}{b b \RightEdge}
                \\
                \LeftEdge & a & a & a & b & b & \RightEdge 
        \end{array}
    \]
    \[ 
        \begin{array}{ccccccccccc}
                \ComplexState{eee}{\LeftEdge \LeftEdge \LeftEdge} &
                \ComplexState{eee}{\LeftEdge \LeftEdge a} &
                \ComplexState{eee}{\LeftEdge a a} &
                \ComplexState{eee}{a a a} &
                \ComplexState{eeo}{a a b} &
                \ComplexState{eoe}{a b b} &
                \ComplexState{oee}{b b a} &
                \ComplexState{eee}{b a a} &
                \\
                \LeftEdge & a & a & a & b & b & a & a & b & b &\RightEdge
        \end{array}
    \]
    \[ 
        \begin{array}{ccccccccccc}
                \ComplexState{eee}{\LeftEdge \LeftEdge \LeftEdge} &
                \ComplexState{eee}{\LeftEdge \LeftEdge a} &
                \ComplexState{eee}{\LeftEdge a a} &
                \ComplexState{eee}{a a a} &
                \ComplexState{eeo}{a a b} &
                \ComplexState{eoe}{a b b} &
                \ComplexState{oee}{b b a} &
                \ComplexState{eee}{b a a} &
                \ComplexState{eee}{a a a} &
                \ComplexState{eeo}{a a b} &
                \\
                \LeftEdge & a & a & a & b & b & a & a & a & b &\RightEdge
        \end{array}
    \]
\end{examplebox}
%
As this example shows, we never need a search window bigger than $2$ because the hidden alphabet can keep track of all the extra information a bigger window would provide.
Turning this intuition into a proof is fairly straight-forward, but requires a loot of bookkeeping via indices.
%
\begin{proof}
    We show that every strictly $k$-local grammar $G_k$ with refined alphabet $\tuple{\Sigma_k,Q_k}$ can be converted into a strictly $2$-local grammar $G_2$ with refined alphabet $\tuple{\Sigma_k,(\Sigma_k \times Q_k)^{k-1}}$ such that $L(G_k) = L(G_2)$.
    Let $G_2$ be the smallest set of bigrams such that if $g \is \dfrac{q_1 \cdots q_k}{\sigma_1 \cdots \sigma_k}$ is a $k$-gram of $G_k$, then $G_2$ contains $g' \is \dfrac{\phi \rho}{\sigma_{k-1} \sigma_k}$, where $\phi \is \dfrac{q_1 \cdots q_{k-1}}{\sigma_1 \cdots \sigma_{k-1}}$ and $\rho \is \dfrac{q_2 \cdots q_k}{\sigma_2 \cdots \sigma_k} \in Q_k^{k-1}$.
    We give an inductive proof that $L(G_2) = L(G_k)$.

    Suppose $w \in L(G_k)$, and that $g_k \is \dfrac{q_1 \cdots q_k}{\sigma_1 \cdots \sigma_k}$ is the refined $k$-gram spanning from the $m$-th to the $(m+k-1)$-th symbol of the $k$-augmented counterpart $\augmented{w}_k$ of $w$.

    For the base case assume $m = 1$.
    Then the first $k-1$ symbols of $g_k$ are left edge markers: $\sigma_i = \LeftEdge$, $1 \leq i < k$, while the $2$-augmented counterpart $\augmented{w}_2$ lacks the first $k-2$ symbols of $\augmented{w}_k$.
    Given the construction above, $G_2$ contains the refined bigram
    \[
        g_2 \is 
        \dfrac{
            \dfrac{
                q_1 \cdots q_{k-1}}
                {\sigma_1 \cdots \sigma_{k-1}}
            \cdot
            \dfrac{
                q_2 \cdots q_k}
                {\sigma_2 \cdots \sigma_k}
            }
            {\LeftEdge\qquad \sigma_k},
    \]
    which can be assigned to the first two positions of $\augmented{w}_2$.
    In the other direction, if $g_2$ is assigned to the first $2$ positions of $\augmented{w}_2$, then $g_k$ can be assigned to the first $k$ positions of $\augmented{w}_k$.
    Since $g_2 \in G_2$ iff $g_k \in G_k$, the first $2$ positions of $\augmented{w}_2$ are well-formed wrt $G_2$ iff the first $k$ positions of $\augmented{w}_k$ are well-formed with respect to $G_k$.

    For arbitrary $m$, suppose that $g_k$ spans from the $m$-th to the $n$-th position of $\augmented{w}_k$, where $n = m + k - 1$.
    By our induction hypothesis, some bigram spans the positions in $\augmented{w}_2$ that correspond to $n - 2$ and $n - 1$ of $\augmented{w}_k$--- namely $n - (k - 2) - 2 = m - 1$ and $n - (k - 2) - 1 = m$, respectively.
    Moreover, the second component of this bigram is
    %
    \[
        \dfrac{
            \dfrac{
                q_1 \cdots q_{k-1}}
                {\sigma_1 \cdots \sigma_{k-1}}
            }
            {\sigma_{k-1}}
            .
    \]
    By our construction, then, there is a $g_2 \in G_2$ that spans from $m$ to $m+1$ and has the shape
    \[
        \dfrac{
            \dfrac{
                q_1 \cdots q_{k-1}}
                {\sigma_1 \cdots \sigma_{k-1}}
            \cdot
            \dfrac{
                q_2 \cdots q_k}
                {\sigma_2 \cdots \sigma_k}
            }
            {\sigma_{k-1}\qquad \sigma_k}
    \]
    iff $g_k \in G_k$.
\end{proof}

Theorem~\ref{thm:REG_SL2} shows that every refined strictly local language is refined strictly $2$-local.
Rather than the infinite hierarchies of increasing complexity that we saw with the strictly local and strictly piecewise languages, this class is flat, at least with respect to whether a language can be generated by a refined strictly $2$-local language.
To emphasize this flatness, we don't just drop the locality parameter --- which might be mistaken as refering to a more powerful class that is the union of all refined strictly $k$-local languages --- but coin a completely new term.
%
\begin{definition}[Regular Languages]
    A language is \emph{regular} iff it is generated by a refined strictly $2$-local grammar.
\end{definition}
%
Regular languages are one of the most important classes of string languages in computer science and have been defined in numerous equivalent ways.
We do not have time to look at all of them, but most of them are covered in every decent textbook on formal language theory such as \citet{Sipser05}, \citet{Kozen97}, or \citet{HopcroftUllman79} (listed in increasing order of difficulty).

At least one of these equivalent definitions of regular languages can be inferred rather easily from example~\ref{ex:REG_HiddenTranslation}, though.
In this example, we saw that parts of a $k$-gram can be crammed into the hidden alphabet of a bigram.
But in principle we could do the same thing to the bigram and copy the overt symbols into the hidden alphabet, too.
In this case, we can infer the state of a node purely from the label of that node and the state of the preceding node; the label of the preceding state is no longer needed.
Consequently, every bigram $\kState{p q}{b a}$ can be represented by a simple graph.
%
\begin{center}
    \input{./img/tikz/REG_BigramAutomaton.tikz}
\end{center}
%
We can think of this graph as a machine or \emph{automaton} that switches from state $p$ to $q$ if it reads in an $a$.
The whole grammar is an automaton that combines the mini-automata of all the bigrams.
For the language in example~\ref{ex:REG_HiddenTranslation}, the automaton is actually much easier to understand than the refined grammar we constructed.
%
\begin{center}
    \input{./img/tikz/REG_3aEvenbAutomaton.tikz}
\end{center}
%
The graph uses start to indicate which state(s) may be assigned to the first node, whereas only circled states may be assigned to the final node.
The runs for the three test strings from the previous example now look slightly different, but they still lead to the same conclusions.
%
\[
    \begin{array}{ccccc}
            0 & 1 & 2 & o & e\\
            a & a & a & b & b 
    \end{array}
\]
\[ 
    \begin{array}{ccccccccc}
            0 & 1 & 2 & o & e & 0 & 1 & &\\
            a & a & a & b & b & a & a & b & b 
    \end{array}
\]
\[ 
    \begin{array}{ccccccccc}
            0 & 1 & 2 & o & e & 0 & 1 & 2 & o\\
            a & a & a & b & b & a & a & a & b 
    \end{array}
\]

\begin{definition}[Finite-State Automaton]
    A \emph{finite state automaton} (FSA) is a quintuple $A \is \tuple{\Sigma, Q, I, F, \Delta}$, where
    %
    \begin{itemize}
        \item $\Sigma$ is an alphabet,
        \item $Q$ is a finite set of states,
        \item $I \subseteq Q$ is the set of \emph{initial} states,
        \item $F \subseteq Q$ is the set of \emph{final} states,
        \item $\Delta \subseteq Q \times \Sigma \times Q$ is a finite set of transition rules.
    \end{itemize}
    %
    The FSA is \emph{deterministic} iff $I$ is a singleton set and $\Delta$ contains no two $\tuple{p,a,q}$ and $\tuple{p,a,r}$ with $q \neq r$.
    Otherwise it is non-deterministic.
\end{definition}

determinization via powerset construction

\section{Properties of Regular Languages}

cylindrification

boolean closure

relabeling closure

closure under reversal

Myhill-Nerode characterization

closure under finite-state transductions
