\chapter{Adding Probabilities}
\label{cha:PSL}

\begin{itemize}
    \item probabilistic version: switch to different monoid (0,1,min; 0,1,*; [0,1],*)
    \item inferring probabilities
    \item smoothing techniques
\end{itemize}

\begin{align*}
    f(aba) & =
            f(\LeftEdge a)
            \times
            f(ab)
            \times
            f(ba)
            \times
            f(a\RightEdge)
            \\
            & =
            1
            \times
            1
            \times
            1
            \times
            0
            \\
            & =
            0
\end{align*}

\begin{center}
    \begin{minipage}{.35\linewidth}
        \begin{align*}
            f(aba)
            &= 1 \times (1 \times (1 \times 0)) \\
            &= 1 \times (1 \times 0) \\
            &= 1 \times 0\\
            &= 0
        \end{align*}
    \end{minipage}
    %
    \begin{minipage}{.2\linewidth}
        \begin{align*}
            &= 1 \mathrel{\text{min}} (1 \mathrel{\text{min}} (1 \mathrel{\text{min}} 0)) \\
            &= 1 \mathrel{\text{min}} (1 \mathrel{\text{min}} 0) \\
            &= 1 \mathrel{\text{min}} 0\\
            &= 0
        \end{align*}
    \end{minipage}
    %
    \begin{minipage}{.25\linewidth}
        \begin{align*}
            &= 1 \wedge (1 \wedge (1 \wedge 0)) \\
            &= 1 \wedge (1 \wedge 0) \\
            &= 1 \wedge 0\\
            &= 0
        \end{align*}
    \end{minipage}
\end{center}

What they have in common:
%
\begin{itemize}
    \item set is closed under operation
    \item operation is associative
    \item 1 is an identity element
\end{itemize}
%
They're \emph{monoids}.
Use \semimult\ as a general placeholder for operations that obey these properties.
%
\[
    f(a_1 \cdot a_2 \cdots a_{n-1} \cdot a_n) \is
        f(a_1 \cdot a_2) \semimult \cdots \semimult f(a_{n-1} \cdot a_n)
\]
%
\begin{itemize}
    \item 1 is the unique top element
    \item 0 is the unique bottom element
\end{itemize}
%
Other monoids:
%
\begin{itemize}
    \item set of all n-grams in string
    \item number of bigram tokens (no top element!)
\end{itemize}
%
Here 0 is the identity, so we use \semiadd\ instead.

\begin{center}
    \pythonfile[firstline=5]{./code/monoid_scanner/monoid_bigram_scanner.py}
\end{center}
%
In order to turn this into a standard recognizer, we have to supply two functions that, respectively, determine for each bigram whether it is licensed by the grammar and compute compound grammaticality values.
%
\begin{center}
    \pythonfile[firstline=5]{./code/monoid_scanner/ngram_grammatical.py}
\end{center}
%
The set of all bigrams in the string, on the other hand, is computed by feeding the two functions below into the monoid scanner.
%
\begin{center}
    \pythonfile[firstline=5]{./code/monoid_scanner/ngram_set.py}
\end{center}
%
And if we want to know how many bigram tokens occur in the string, we switch to yet another pair of functions.
%
\begin{center}
    \pythonfile[firstline=5]{./code/monoid_scanner/ngram_token.py}
\end{center}

advantages: modularity (look at how small those functions are!), easy to maintain and debug, any optimization to monoid_scanner optimizes a variety of scanners

\begin{center}
    \pythonfile[firstline=5]{./code/monoid_scanner/ngram_probabilistic.py}
\end{center}

%hw: generalize monoid_scanner to n-grams
%hw: use monoid parser to count number of tokens for each occurring n-gram
